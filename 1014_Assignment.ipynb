{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5Y80rIvHCqcltUtvSyTnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriver42/ESAA/blob/%ED%95%84%EC%82%AC-%EA%B3%BC%EC%A0%9C/1014_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CH9 추천 시스템\n",
        "\n"
      ],
      "metadata": {
        "id": "a4EDwyskqZQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###01 추천 시스템의 개요와 배경\n",
        "- 유형:\n",
        " - 콘텐츠 기반 필터링 방식\n",
        " - 협업 필터링 방식"
      ],
      "metadata": {
        "id": "dwOeNHMDqqul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###02 콘텐츠 기반 필터링 추천 시스템\n",
        ": 사용자가 선호하는 아이템을 기반으로 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식"
      ],
      "metadata": {
        "id": "Qa6-Ct9Eq6Bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###03 최근접 이웃 협업 필터링\n",
        ": 사용자 행동 양식(User Behavior)만을 기반으로 추천을 수행하는 방식\n",
        "- 목표: 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 에측 평가하는 것\n",
        "- 방식:\n",
        "  - 최근접 이웃 방식(메모리 협업 필터링)\n",
        "    - 사용자 기반: 사용자 기반 최근접 이웃 방식은 특정 사용자와 유사한 다른 사용자를 Top-N으로 선정해 이\n",
        "Top-N 사용자가 좋아하는 아이템을 추천하는 방식\n",
        "\n",
        "    - 아이템 기반: 아이템이 가지는\n",
        "속성과는 상관없이 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 기준이 되는 알고리즘, 대부분 이 방식을 사용함.\n",
        "  - 잠재 요인 방식\n",
        "  - 추천 시스템의 유사도 측정에 코사인 유사도 사용됨."
      ],
      "metadata": {
        "id": "hTa7OHu9rK3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##04. 잠재 요인 협업 필터링\n",
        "- 잠재 요인 협업 필터링: 사용자-아이템 평점 행렬 데이터만을 이용해 말 그대로 ‘잠재 요인’을 끄집어내는 것을 의미\n",
        "- ‘잠재 요인’을 기반으로 다차원 희소 행렬인 사용자一아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재\n",
        "요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬（즉, 잠재 요인-아이템 행렬）로 분해할 수 있으며, 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자—아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성하는 방식\n",
        "\n",
        "**행렬 분해의 이해**\n",
        "- 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법\n",
        "  -  SVD(Singular Vector Decomposition), NMF(Non—Negative Matrix Factorization)\n",
        "- M개의 사용자행과 N개의 아이템열을 가진 평점 행렬 R은 M X N 차원으로 구성\n",
        "  - 행렬 분해를 통해서 사용자-K 차원 잠재 요인 행렬 P(MXK 차원）와 K 차원 잠재 요인 - 아이템 행렬 Q.T(KXN 차원）로 분해됨.(Q 는 아이템-잠재 요인 행렬, Q.T 는 Q 의 전치 행렬인 잠재 요인-아이템 행렬)\n",
        "\n",
        "**확률적 경사 하강법을 이용한 행렬 분해**\n",
        "- P 와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추해내는 것\n",
        "1. P와 Q를 임의의 값을 가진 행렬로 설정\n",
        "2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 해당하는 오류 값을 계산\n",
        "3. 이 오류 값을 최소화할 수 있도록 P와 Q 행렬을 적절한 값으로 각각 업데이트\n",
        "4. 만족할 만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화\n",
        "- 일반적으로 사용자-아이템 평점 행렬의 경우 행렬 분해를 위해서 단순히 예측 오류값의 최소화와 학습 시 과적합을 피하기 위해서 규제를 반영한 비용 함수를 적용함.\n",
        "- SDG 기반의 행렬 분해: L2 규제를 반영해 실제 R 행렬 값과 예측 R 행렬 값의 차이를 최소화하는 방향성을 가지고 P행렬과 Q행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R 행렬을 구하는 방식\n"
      ],
      "metadata": {
        "id": "_wHoNpljrmwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgpMCMldPJz0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#원본 행렬 R 생성, 분해 행렬 이와 Q 초기화, 잠재 요인 차원 유는 3으로 설정.\n",
        "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
        "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
        "              [np.NaN, np.NaN, 3, 4, 4],\n",
        "              [5, 2, 1, 2, np.NaN]])\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "#P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items, K))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R, P, Q, non_zeros):\n",
        "    error = 0\n",
        "    #두 개의 분해된 행렬 으와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "    full_pred_matrix = np.dot(P, Q.T)\n",
        "\n",
        "    #실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    return rmse\n"
      ],
      "metadata": {
        "id": "g8RRhmOllZWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R > 0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
        "non_zeros = [(i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j]>0]\n",
        "\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "#SGD 기법으로 우와 Q 매트릭스를 계속 업데이트.\n",
        "for step in range(steps):\n",
        "  for i, j, r in non_zeros:\n",
        "    #실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    eij = r - np.dot(P[i, :], Q[j, :].T)\n",
        "    #Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :] = P[i, :] + learning_rate*(eij * Q[j, :] - r_lambda*P[i, :])\n",
        "    Q[j, :] = Q[j, :] + learning_rate*(eij * P[i, :] - r_lambda*Q[j, :])\n",
        "\n",
        "    rmse = get_rmse(R, P, Q, non_zeros)\n",
        "    if (step % 50) == 0 :\n",
        "      print(\"### iteration step : \", step, \" rmse : \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM3L1sqmnLrZ",
        "outputId": "dfc0b5f6-4fb6-4217-a8a0-658481f6a3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step :  0  rmse :  0.016599129218140208\n",
            "### iteration step :  0  rmse :  0.01668830060775919\n",
            "### iteration step :  0  rmse :  0.016548113949791696\n",
            "### iteration step :  0  rmse :  0.01647540947076357\n",
            "### iteration step :  0  rmse :  0.01658935692516356\n",
            "### iteration step :  0  rmse :  0.016603539486165532\n",
            "### iteration step :  0  rmse :  0.016426936856238406\n",
            "### iteration step :  0  rmse :  0.016404876258812897\n",
            "### iteration step :  0  rmse :  0.01608305843990478\n",
            "### iteration step :  0  rmse :  0.0162146619204775\n",
            "### iteration step :  0  rmse :  0.01630027086162528\n",
            "### iteration step :  0  rmse :  0.01655803890814364\n",
            "### iteration step :  50  rmse :  0.016555532685664495\n",
            "### iteration step :  50  rmse :  0.01664375695415199\n",
            "### iteration step :  50  rmse :  0.016502704735255096\n",
            "### iteration step :  50  rmse :  0.01643111453746046\n",
            "### iteration step :  50  rmse :  0.01654535507021205\n",
            "### iteration step :  50  rmse :  0.016559308517824143\n",
            "### iteration step :  50  rmse :  0.01638328614398011\n",
            "### iteration step :  50  rmse :  0.016360941671818313\n",
            "### iteration step :  50  rmse :  0.016038552419729485\n",
            "### iteration step :  50  rmse :  0.016170822501535266\n",
            "### iteration step :  50  rmse :  0.016256889083844987\n",
            "### iteration step :  50  rmse :  0.016513859189388212\n",
            "### iteration step :  100  rmse :  0.016511468267802493\n",
            "### iteration step :  100  rmse :  0.01659889418719999\n",
            "### iteration step :  100  rmse :  0.01645698704445494\n",
            "### iteration step :  100  rmse :  0.01638649971882758\n",
            "### iteration step :  100  rmse :  0.01650103057920073\n",
            "### iteration step :  100  rmse :  0.016514780744198758\n",
            "### iteration step :  100  rmse :  0.016339250245683792\n",
            "### iteration step :  100  rmse :  0.01631663690004423\n",
            "### iteration step :  100  rmse :  0.015993767403263276\n",
            "### iteration step :  100  rmse :  0.016126691990375495\n",
            "### iteration step :  100  rmse :  0.016213206106134435\n",
            "### iteration step :  100  rmse :  0.016469302176442754\n",
            "### iteration step :  150  rmse :  0.016467092813730162\n",
            "### iteration step :  150  rmse :  0.01655384398281284\n",
            "### iteration step :  150  rmse :  0.016411092151467934\n",
            "### iteration step :  150  rmse :  0.016341696621298665\n",
            "### iteration step :  150  rmse :  0.016456515221948957\n",
            "### iteration step :  150  rmse :  0.016470083108455682\n",
            "### iteration step :  150  rmse :  0.016294973366984246\n",
            "### iteration step :  150  rmse :  0.016272103370203867\n",
            "### iteration step :  150  rmse :  0.015948829826065335\n",
            "### iteration step :  150  rmse :  0.016082397709152017\n",
            "### iteration step :  150  rmse :  0.01616935065549075\n",
            "### iteration step :  150  rmse :  0.016424510253994627\n",
            "### iteration step :  200  rmse :  0.016422566624655\n",
            "### iteration step :  200  rmse :  0.016508746262050504\n",
            "### iteration step :  200  rmse :  0.016365160324811254\n",
            "### iteration step :  200  rmse :  0.016296845062150404\n",
            "### iteration step :  200  rmse :  0.016411948804450124\n",
            "### iteration step :  200  rmse :  0.01642535211150005\n",
            "### iteration step :  200  rmse :  0.016250605307735585\n",
            "### iteration step :  200  rmse :  0.0162274886533713\n",
            "### iteration step :  200  rmse :  0.0159038754384808\n",
            "### iteration step :  200  rmse :  0.016038075533398054\n",
            "### iteration step :  200  rmse :  0.016125459106984628\n",
            "### iteration step :  200  rmse :  0.016379631765893563\n",
            "### iteration step :  250  rmse :  0.01637803861491094\n",
            "### iteration step :  250  rmse :  0.016463733336613474\n",
            "### iteration step :  250  rmse :  0.016319324547621406\n",
            "### iteration step :  250  rmse :  0.01625207724524769\n",
            "### iteration step :  250  rmse :  0.016367463438447197\n",
            "### iteration step :  250  rmse :  0.016380717535595193\n",
            "### iteration step :  250  rmse :  0.01620628624345717\n",
            "### iteration step :  250  rmse :  0.01618293112607431\n",
            "### iteration step :  250  rmse :  0.015859033164072455\n",
            "### iteration step :  250  rmse :  0.01599385414367516\n",
            "### iteration step :  250  rmse :  0.016081660174416135\n",
            "### iteration step :  250  rmse :  0.016334805739707706\n",
            "### iteration step :  300  rmse :  0.016333640099037098\n",
            "### iteration step :  300  rmse :  0.016418922923059194\n",
            "### iteration step :  300  rmse :  0.01627370330066989\n",
            "### iteration step :  300  rmse :  0.01620751078736502\n",
            "### iteration step :  300  rmse :  0.016323176619561685\n",
            "### iteration step :  300  rmse :  0.01633629518315277\n",
            "### iteration step :  300  rmse :  0.01616214019624121\n",
            "### iteration step :  300  rmse :  0.01613855335131472\n",
            "### iteration step :  300  rmse :  0.015814417913420267\n",
            "### iteration step :  300  rmse :  0.01594984805886759\n",
            "### iteration step :  300  rmse :  0.016038068192098694\n",
            "### iteration step :  300  rmse :  0.016290155305291112\n",
            "### iteration step :  350  rmse :  0.01628948313524086\n",
            "### iteration step :  350  rmse :  0.01637441588912323\n",
            "### iteration step :  350  rmse :  0.0162283981882612\n",
            "### iteration step :  350  rmse :  0.016163246467923546\n",
            "### iteration step :  350  rmse :  0.016279189004733876\n",
            "### iteration step :  350  rmse :  0.016292184440510178\n",
            "### iteration step :  350  rmse :  0.01611827311783961\n",
            "### iteration step :  350  rmse :  0.01609446009300167\n",
            "### iteration step :  350  rmse :  0.0157701281885833\n",
            "### iteration step :  350  rmse :  0.01590615535985108\n",
            "### iteration step :  350  rmse :  0.015994780976555264\n",
            "### iteration step :  350  rmse :  0.016245785731998592\n",
            "### iteration step :  400  rmse :  0.016245661166174565\n",
            "### iteration step :  400  rmse :  0.01633029642720461\n",
            "### iteration step :  400  rmse :  0.016183494053890343\n",
            "### iteration step :  400  rmse :  0.016119368402168002\n",
            "### iteration step :  400  rmse :  0.016235584599309016\n",
            "### iteration step :  400  rmse :  0.016248468328439493\n",
            "### iteration step :  400  rmse :  0.016074773317268434\n",
            "### iteration step :  400  rmse :  0.016050738690224213\n",
            "### iteration step :  400  rmse :  0.015726246154884056\n",
            "### iteration step :  400  rmse :  0.01586285782292347\n",
            "### iteration step :  400  rmse :  0.01595188003416839\n",
            "### iteration step :  400  rmse :  0.016201784817113825\n",
            "### iteration step :  450  rmse :  0.016202250713951642\n",
            "### iteration step :  450  rmse :  0.01628663337996191\n",
            "### iteration step :  450  rmse :  0.01613906028277785\n",
            "### iteration step :  450  rmse :  0.016075945365187045\n",
            "### iteration step :  450  rmse :  0.016192432087145704\n",
            "### iteration step :  450  rmse :  0.01620521474347753\n",
            "### iteration step :  450  rmse :  0.016031712981819025\n",
            "### iteration step :  450  rmse :  0.016007460536316458\n",
            "### iteration step :  450  rmse :  0.015682838892680944\n",
            "### iteration step :  450  rmse :  0.015820022200533697\n",
            "### iteration step :  450  rmse :  0.015909431879530495\n",
            "### iteration step :  450  rmse :  0.016158224373926302\n",
            "### iteration step :  500  rmse :  0.016159313457805115\n",
            "### iteration step :  500  rmse :  0.016243482023644736\n",
            "### iteration step :  500  rmse :  0.016095152580898338\n",
            "### iteration step :  500  rmse :  0.01603303257352169\n",
            "### iteration step :  500  rmse :  0.01614978661397059\n",
            "### iteration step :  500  rmse :  0.016162478182531703\n",
            "### iteration step :  500  rmse :  0.01598915011289558\n",
            "### iteration step :  500  rmse :  0.015964682981408466\n",
            "### iteration step :  500  rmse :  0.015639960126454765\n",
            "### iteration step :  500  rmse :  0.015777701961088325\n",
            "### iteration step :  500  rmse :  0.015867489792137847\n",
            "### iteration step :  500  rmse :  0.01611516214017394\n",
            "### iteration step :  550  rmse :  0.01611689834373517\n",
            "### iteration step :  550  rmse :  0.016200885941880426\n",
            "### iteration step :  550  rmse :  0.01605181485407698\n",
            "### iteration step :  550  rmse :  0.015990673557519604\n",
            "### iteration step :  550  rmse :  0.0161076916591547\n",
            "### iteration step :  550  rmse :  0.016120301575067737\n",
            "### iteration step :  550  rmse :  0.01594713052013551\n",
            "### iteration step :  550  rmse :  0.015922451299964287\n",
            "### iteration step :  550  rmse :  0.015597652058240393\n",
            "### iteration step :  550  rmse :  0.015735939123239413\n",
            "### iteration step :  550  rmse :  0.015826095656062064\n",
            "### iteration step :  550  rmse :  0.01607264374956633\n",
            "### iteration step :  600  rmse :  0.016075043554648307\n",
            "### iteration step :  600  rmse :  0.016158878806012415\n",
            "### iteration step :  600  rmse :  0.016009080998089474\n",
            "### iteration step :  600  rmse :  0.01594890194063439\n",
            "### iteration step :  600  rmse :  0.016066180813285934\n",
            "### iteration step :  600  rmse :  0.016078718033537016\n",
            "### iteration step :  600  rmse :  0.01590568969745626\n",
            "### iteration step :  600  rmse :  0.015880800545501103\n",
            "### iteration step :  600  rmse :  0.015555947117562849\n",
            "### iteration step :  600  rmse :  0.015694766001632377\n",
            "### iteration step :  600  rmse :  0.015785281704919545\n",
            "### iteration step :  600  rmse :  0.016030704589303422\n",
            "### iteration step :  650  rmse :  0.01603377826811392\n",
            "### iteration step :  650  rmse :  0.016117485979662047\n",
            "### iteration step :  650  rmse :  0.015966976514583127\n",
            "### iteration step :  650  rmse :  0.015907743043305278\n",
            "### iteration step :  650  rmse :  0.016025279379843185\n",
            "### iteration step :  650  rmse :  0.01603775243613749\n",
            "### iteration step :  650  rmse :  0.01586485450415884\n",
            "### iteration step :  650  rmse :  0.015839757214525952\n",
            "### iteration step :  650  rmse :  0.015514869542813102\n",
            "### iteration step :  650  rmse :  0.015654206781781872\n",
            "### iteration step :  650  rmse :  0.015745072092879515\n",
            "### iteration step :  650  rmse :  0.015989371466084153\n",
            "### iteration step :  700  rmse :  0.015993124181877236\n",
            "### iteration step :  700  rmse :  0.01607672592032339\n",
            "### iteration step :  700  rmse :  0.01592551992410826\n",
            "### iteration step :  700  rmse :  0.01586721528414552\n",
            "### iteration step :  700  rmse :  0.015985005774077164\n",
            "### iteration step :  700  rmse :  0.015997422812337632\n",
            "### iteration step :  700  rmse :  0.015824644627975296\n",
            "### iteration step :  700  rmse :  0.01579934069572425\n",
            "### iteration step :  700  rmse :  0.015474436764933609\n",
            "### iteration step :  700  rmse :  0.015614278896473006\n",
            "### iteration step :  700  rmse :  0.015705484265846774\n",
            "### iteration step :  700  rmse :  0.01594866405691241\n",
            "### iteration step :  750  rmse :  0.015953096814424327\n",
            "### iteration step :  750  rmse :  0.016036611379525605\n",
            "### iteration step :  750  rmse :  0.015884723977027716\n",
            "### iteration step :  750  rmse :  0.015827331379879912\n",
            "### iteration step :  750  rmse :  0.0159453727207348\n",
            "### iteration step :  750  rmse :  0.015957741531064645\n",
            "### iteration step :  750  rmse :  0.01578507383468499\n",
            "### iteration step :  750  rmse :  0.015759564508365288\n",
            "### iteration step :  750  rmse :  0.015434660593571264\n",
            "### iteration step :  750  rmse :  0.015574994204660433\n",
            "### iteration step :  750  rmse :  0.015666530134758213\n",
            "### iteration step :  750  rmse :  0.015908596148844503\n",
            "### iteration step :  800  rmse :  0.015913706600649693\n",
            "### iteration step :  800  rmse :  0.015997150417037573\n",
            "### iteration step :  800  rmse :  0.015844596677447573\n",
            "### iteration step :  800  rmse :  0.0157880993594357\n",
            "### iteration step :  800  rmse :  0.015906388266137887\n",
            "### iteration step :  800  rmse :  0.015918716305922932\n",
            "### iteration step :  800  rmse :  0.015746151022199246\n",
            "### iteration step :  800  rmse :  0.01572043734729663\n",
            "### iteration step :  800  rmse :  0.015395548220191613\n",
            "### iteration step :  800  rmse :  0.015536359987778133\n",
            "### iteration step :  800  rmse :  0.015628217066414492\n",
            "### iteration step :  800  rmse :  0.015869176685154265\n",
            "### iteration step :  850  rmse :  0.015874959807450906\n",
            "### iteration step :  850  rmse :  0.015958347250281047\n",
            "### iteration step :  850  rmse :  0.015805142141232256\n",
            "### iteration step :  850  rmse :  0.01574952341329542\n",
            "### iteration step :  850  rmse :  0.015868056625755213\n",
            "### iteration step :  850  rmse :  0.01588035103780662\n",
            "### iteration step :  850  rmse :  0.015707881102167007\n",
            "### iteration step :  850  rmse :  0.015681963957159175\n",
            "### iteration step :  850  rmse :  0.01535710305859416\n",
            "### iteration step :  850  rmse :  0.015498379784073172\n",
            "### iteration step :  850  rmse :  0.015590548712719254\n",
            "### iteration step :  850  rmse :  0.015830410640611893\n",
            "### iteration step :  900  rmse :  0.01583685929460719\n",
            "### iteration step :  900  rmse :  0.015920202961364482\n",
            "### iteration step :  900  rmse :  0.015766361310542442\n",
            "### iteration step :  900  rmse :  0.015711604600484808\n",
            "### iteration step :  900  rmse :  0.015830378889653142\n",
            "### iteration step :  900  rmse :  0.015842646516765615\n",
            "### iteration step :  900  rmse :  0.015670265733029275\n",
            "### iteration step :  900  rmse :  0.01564414585942261\n",
            "### iteration step :  900  rmse :  0.015319325444728325\n",
            "### iteration step :  900  rmse :  0.015461054082926378\n",
            "### iteration step :  900  rmse :  0.015553525700392153\n",
            "### iteration step :  900  rmse :  0.015792299749517028\n",
            "### iteration step :  950  rmse :  0.015799405144745274\n",
            "### iteration step :  950  rmse :  0.015882716083172047\n",
            "### iteration step :  950  rmse :  0.015728252546411244\n",
            "### iteration step :  950  rmse :  0.015674341434605523\n",
            "### iteration step :  950  rmse :  0.01579335360722126\n",
            "### iteration step :  950  rmse :  0.015805601004138196\n",
            "### iteration step :  950  rmse :  0.01563330392715959\n",
            "### iteration step :  950  rmse :  0.015606981954605359\n",
            "### iteration step :  950  rmse :  0.015282213216846056\n",
            "### iteration step :  950  rmse :  0.015424380900176152\n",
            "### iteration step :  950  rmse :  0.015517146202199964\n",
            "### iteration step :  950  rmse :  0.01575484310887397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix = np.dot(P, Q.T)\n",
        "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iymMVWG7oQPU",
        "outputId": "528a1603-5d9c-49a9-b62e-4ea804bc4d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 1.096 1.291 2.001 1.695]\n",
            " [6.267 4.978 0.878 2.982 1.003]\n",
            " [6.551 0.886 2.987 3.978 3.986]\n",
            " [4.969 2.005 1.007 2.013 1.276]]\n"
          ]
        }
      ]
    }
  ]
}